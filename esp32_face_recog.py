import cv2
import numpy as np
import face_recognition
import os
import threading
import websocket
import time

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) ØªØ­Ù…ÙŠÙ„ ÙˆØµÙ†Ø¹ encodings Ù„Ù„ÙˆØ¬ÙˆÙ‡ Ù…Ù† Ù…Ø¬Ù„Ù‘Ø¯ 'persons'
path = 'persons'
images = []
classNames = []

for fname in os.listdir(path):
    img = cv2.imread(os.path.join(path, fname))
    if img is None:
        continue
    images.append(img)
    classNames.append(os.path.splitext(fname)[0])

def findEncodings(imgs):
    encs = []
    for im in imgs:
        rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
        boxes = face_recognition.face_encodings(rgb)
        if boxes:
            encs.append(boxes[0])
    return encs

knownEncodings = findEncodings(images)
print("âœ… Encoding Complete for:", classNames)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2) ÙØªØ­ WebSocket Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ ÙØ±ÙŠÙ…Ø§Øª JPEG
latest_frame = None

def on_message(ws, message):
    global latest_frame
    # Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù‡Ù†Ø§ Ø¨Ø§ÙŠÙ†Ø§Ø±ÙŠ JPEG
    arr = np.frombuffer(message, dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    latest_frame = img

def on_open(ws):
    print("ğŸ”Œ WebSocket opened to /Camera")

def on_error(ws, error):
    print("âŒ WebSocket error:", error)

def on_close(ws, code, reason):
    print("ğŸ“´ WebSocket closed")

def start_ws():
    ws_url = "ws://192.168.4.1/Camera"
    ws = websocket.WebSocketApp(ws_url,
                                on_open=on_open,
                                on_message=on_message,
                                on_error=on_error,
                                on_close=on_close)
    ws.run_forever()

# Ø´ØºÙ‘Ù„ WebSocket ÙÙŠ Ø«Ø±ÙŠØ¯ daemon
threading.Thread(target=start_ws, daemon=True).start()
time.sleep(2)  # Ø¯Ù‚Ø§Ø¦Ù‚ Ù„Ù„Ø§ØªØµØ§Ù„

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3) Ø§Ù„Ù„ÙˆØ¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬ÙˆÙ‡
print("â–¶ï¸ Starting main loop. Press 'q' to quit.")
while True:
    if latest_frame is None:
        time.sleep(0.01)
        continue

    frame = latest_frame.copy()
    # Ø®ÙÙ‘Ø¶ Ø¯Ù‚Ù‘Ø© Ø§Ù„ÙØ±ÙŠÙ… Ù„Ù„ØªØ³Ø±ÙŠØ¹
    small = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
    rgb_small = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)

    # Ø§ÙƒØªØ´Ø§Ù Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ùˆ encodings
    face_locs = face_recognition.face_locations(rgb_small)
    face_encs = face_recognition.face_encodings(rgb_small, face_locs)

    for enc, loc in zip(face_encs, face_locs):
        distances = face_recognition.face_distance(knownEncodings, enc)
        idx = np.argmin(distances)
        if distances[idx] < 0.6:
            name = classNames[idx].upper()
            y1, x2, y2, x1 = [v * 4 for v in loc]
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
            cv2.rectangle(frame, (x1, y2 - 35), (x2, y2), (0, 0, 255), cv2.FILLED)
            cv2.putText(frame, name, (x1 + 6, y2 - 6),
                        cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)

    cv2.imshow('ESP32-CAM Face Recognition', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()
